{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import json\n",
    "import pycountry \n",
    "import re\n",
    "import urllib\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_df(urls, clean_empty = False , attrs = {}, helper = None):\n",
    "    '''\n",
    "    Input:\n",
    "        urls : url from which data is taken.\n",
    "        clean_empty : remove empty column.\n",
    "        attrs : html attr. dict tag while more then on table e.g. {'class' : 'class_name'}.\n",
    "        helper : helper function for cleaning df.\n",
    "    Output:\n",
    "        df : dataframe\n",
    "    '''\n",
    "    df_l = []\n",
    "    for url in urls:\n",
    "        url_content = requests.get(url).text\n",
    "        soup = bs(url_content, \"lxml\")\n",
    "        table = str(soup.find(\"table\", attrs=attrs))\n",
    "        df = pd.read_html(str(table))[0]\n",
    "    \n",
    "        if clean_empty :\n",
    "            df = df.loc[:, ~df.isnull().all(axis = 0)]\n",
    "        \n",
    "        if helper:\n",
    "            df = helper(df) \n",
    "        df_l.append(df)\n",
    "    return pd.concat(df_l,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc_dict(series):\n",
    "    '''\n",
    "    input:\n",
    "        series: series of unique ip address.\n",
    "    output:\n",
    "        res: dict containing country code, latitude, longitude.\n",
    "    '''\n",
    "    def ip_loc(x):\n",
    "        '''\n",
    "        input:\n",
    "            x : ip address\n",
    "        output:\n",
    "            dictionary which contain country,latitude and longitude.\n",
    "        '''\n",
    "        res = {}\n",
    "        url = \"https://geolocation-db.com/jsonp/\"+x\n",
    "        with urllib.request.urlopen(url) as url:\n",
    "            data = json.loads(url.read().decode().split(\"(\")[1].strip(\")\"))\n",
    "        res = {\"country_code\":data[\"country_code\"], 'latitude':data['latitude'],'longitude':data['longitude']}\n",
    "        try:\n",
    "            res['alpha_3'] = pycountry.countries.get(alpha_2=country).alpha_3\n",
    "        except:\n",
    "            res['alpha_3'] = 'Not found'\n",
    "        return res\n",
    "    \n",
    "    result = {}\n",
    "    for ip in tqdm(series):\n",
    "        result[ip] = ip_loc(ip)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_parser_regex(strs):\n",
    "    '''\n",
    "    input:\n",
    "        strs : log string.\n",
    "    output:\n",
    "        return a dictionary which contain all element of log string.\n",
    "    '''\n",
    "    finder = [r'(?P<ip>\\A\\w+[.]\\w+[.]+\\w+[.]+\\w+)',\n",
    "              r'(?P<RFC931>\\S+)',\n",
    "              r'(?P<user>\\S+)',\n",
    "              r'\\[(?P<date>\\d{2}/[a-zA-Z]{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2}) (?P<gmt>[+-]\\d{4})]',\n",
    "              r'\"(?P<action>.*) HTTP/\\d*\\.*\\d*\"',\n",
    "              r'(?P<status>[0-9]*)',\n",
    "              r'(?P<size>\\S*)',\n",
    "              r'\"(?P<referrer>.*)\" \"(?P<browser>.*)\"']\n",
    "    m = re.search(' '.join(finder),strs)\n",
    "    return m.groupdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_df(df,col_name ,columns = [] ):\n",
    "    '''\n",
    "    input: \n",
    "        df : dataframe\n",
    "        col_name : column name of dataframe on which we need to apply function.\n",
    "        columns : column name for new dataframe.\n",
    "    output:\n",
    "        return new dataframe.\n",
    "    '''\n",
    "    def log_parser(strs):\n",
    "        '''\n",
    "        input:\n",
    "            str_ : log string.\n",
    "        output:\n",
    "            return a dictionary which contain all element of log string.\n",
    "        '''\n",
    "        find = {}\n",
    "        find['IP'] = strs.split()[0]\n",
    "        find['RFC931'] = strs.split()[1]\n",
    "        find['USER'] = strs.split()[2]\n",
    "        find['Date'] = strs.split('[')[1].split()[0]\n",
    "        find['GMT'] = strs.split('[')[1].split()[1].strip(']')\n",
    "        try:\n",
    "            if 'HTTP' in strs.split('\"')[1].split()[-1]:\n",
    "                find['action'] =  strs.split('\"')[1].replace(strs.split('\"')[1].split()[2],'').strip()\n",
    "            else:\n",
    "                find['action'] =  strs.split('\"')[1].strip()\n",
    "        except:\n",
    "            find['action'] = '-'\n",
    "        try:\n",
    "            find['status'] = strs.split('\"')[2].strip().split()[0]\n",
    "        except:\n",
    "            find['status'] = '-'\n",
    "        try:\n",
    "            find['size'] = strs.split('\"')[2].strip().split()[1]\n",
    "        except:\n",
    "            find['size'] = '-'\n",
    "        try:\n",
    "            find['referrer'] = strs.strip().split('\"')[3]\n",
    "        except:\n",
    "            find['referrer'] ='-'\n",
    "        try:\n",
    "            find['browser'] = strs.strip().split('\"')[5]\n",
    "        except:\n",
    "            find['browser'] = '-'\n",
    "        \n",
    "        return find\n",
    "    df = pd.DataFrame(list(df[col_name].apply(log_parser).values) )\n",
    "    if len(df.columns) == len(columns):\n",
    "        df.columns = columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XSS_finder(strs):\n",
    "    flag = 0\n",
    "    l1 = ['<','>','\\\\','`']\n",
    "    l2 = ['/',')','(']\n",
    "    for char in l1:\n",
    "        aasci_encoding = '%'+hex(ord(char)).replace('0x','')\n",
    "        if (char in strs) or (aasci_encoding in strs):\n",
    "            flag = 1\n",
    "            break\n",
    "    if flag != 1:\n",
    "        try:\n",
    "            req_str = ''.join(str_.split('?')[1:])\n",
    "            for char in l2:\n",
    "                aasci_encoding = '%'+hex(ord(char)).replace('0x','')\n",
    "                if (char in req_str) or (aasci_encoding in req_str):\n",
    "                    flag = 1\n",
    "                    break\n",
    "        except:\n",
    "            pass\n",
    "    return bool(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_location_data(df,column,keys):\n",
    "    def loc_dict(series):\n",
    "        '''\n",
    "        input:\n",
    "            series: series of unique ip address.\n",
    "        output:\n",
    "            res: dict contain country code, lat, long.\n",
    "        '''\n",
    "        def ip_loc(x):\n",
    "            '''\n",
    "            input:\n",
    "                x : ip address\n",
    "            output:\n",
    "                dictionary which contain country,latitude and longitude.\n",
    "            '''\n",
    "            res = {}\n",
    "            url = \"https://geolocation-db.com/jsonp/\"+x\n",
    "            with urllib.request.urlopen(url) as url:\n",
    "                data = json.loads(url.read().decode().split(\"(\")[1].strip(\")\"))\n",
    "            res = {\"country_code\":data[\"country_code\"], 'latitude':data['latitude'],'longitude':data['longitude']}\n",
    "            try:\n",
    "                res['alpha_3'] = pycountry.countries.get(alpha_2=res[\"country_code\"]).alpha_3\n",
    "            except:\n",
    "                res['alpha_3'] = 'Not found'\n",
    "            return res\n",
    "\n",
    "        result = {}\n",
    "        for ip in tqdm(series):\n",
    "            result[ip] = ip_loc(ip)\n",
    "        return result\n",
    "    \n",
    "    loc_dict = loc_dict_maker(df[column].unique())\n",
    "    for key in keys:\n",
    "        df[key] = df[column].apply(lambda x: loc_dict[x][key])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha3code(column):\n",
    "    '''\n",
    "    input:\n",
    "        column : pandas series.\n",
    "    output:\n",
    "        return 3-leter country code\n",
    "    '''\n",
    "    CODE=[]\n",
    "    for country in column:\n",
    "        try:\n",
    "            code=pycountry.countries.get(alpha_2=country).alpha_3\n",
    "            CODE.append(code)\n",
    "        except:\n",
    "            CODE.append('None')\n",
    "    return CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
